{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting and EDA for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting env var\n",
    "secrets = dotenv_values()\n",
    "\n",
    "host =secrets['DB_HOST']\n",
    "name = secrets['DB_NAME']\n",
    "user = secrets['DB_USER']\n",
    "pwd = secrets['DB_PWD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7043\n"
     ]
    }
   ],
   "source": [
    "# Connecting to DB\n",
    "\n",
    "connection = pymysql.connect(\n",
    "    host = host,\n",
    "    user = user,\n",
    "    password = pwd,\n",
    "    database = name\n",
    "    )\n",
    "\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT * FROM churn_status\")\n",
    "\n",
    "results = cursor.fetchall()\n",
    "\n",
    "print(len(results))\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Done from local data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "ACC_PATH = \"data_given/1_account.csv\"\n",
    "ACC_USAGE_PATH = \"data_given/2_account_usage.csv\"\n",
    "CHURN_STATUS_PATH = \"data_given/3_churn_status.csv\"\n",
    "CITY_PATH = \"data_given/4_city.csv\"\n",
    "CUSTOMER_PATH = \"data_given/5_customer.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(df:pd.DataFrame)->dict:\n",
    "    \"\"\"\n",
    "    Runs through the columns of a dataframe and prints the unique values of each column. \n",
    "    \"\"\"\n",
    "    dict_unique_values = {}\n",
    "    for cols in df.columns:\n",
    "        dict_unique_values[cols] = df[cols].unique()\n",
    "    return dict_unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NaN_count(df:pd.DataFrame)->dict:\n",
    "    \"\"\"\n",
    "    Returns the number of NaN values for each column in a dictionary.\n",
    "    \"\"\"\n",
    "    nan_count = df.isna().sum().to_dict()\n",
    "    return nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocess_acc_df(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses the account dataframe as below:\n",
    "\n",
    "    Converts follow columns (yes/no) to 1/0\n",
    "    - has_internet_service\n",
    "    - has_phone_service\n",
    "    - has_unlimited_data\n",
    "    - has_multiple_lines\n",
    "    - has_premium_tech_support\n",
    "    - has_online_security\n",
    "    - has_online_backup\n",
    "    - has_device_protection\n",
    "    - paperless_billing\n",
    "\n",
    "    Converts follow columns to ordinal values:\n",
    "    - contract_type (one-year, month-to-month, two-year) => (1,0,2) \n",
    "\n",
    "    One-hot encodes following columns:\n",
    "    - payment_method\n",
    "    - internet_type\n",
    "\n",
    "    Scales following columns:\n",
    "    - tenure_months\n",
    "    \"\"\"\n",
    "    # Creating a new df\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # Copying over account_id\tcustomer_id\ttenure_months\n",
    "    output_df['account_id'] = df['account_id']\n",
    "    output_df['customer_id'] = df['customer_id']\n",
    "\n",
    "    # Converting yes/no to 1/0\n",
    "    mapping = {'Yes':1, 'No':0}\n",
    "\n",
    "    output_df['has_internet_service'] = df['has_internet_service'].map(mapping)\n",
    "    output_df['has_phone_service'] = df['has_phone_service'].map(mapping)\n",
    "    output_df['has_unlimited_data'] = df['has_unlimited_data'].map(mapping)\n",
    "    output_df['has_multiple_lines'] = df['has_multiple_lines'].map(mapping)\n",
    "    output_df['has_premium_tech_support'] = df['has_premium_tech_support'].map(mapping)\n",
    "    output_df['has_online_security'] = df['has_online_security'].map(mapping)\n",
    "    output_df['has_online_backup'] = df['has_online_backup'].map(mapping)\n",
    "    output_df['has_device_protection'] = df['has_device_protection'].map(mapping)\n",
    "    output_df['paperless_billing'] = df['paperless_billing'].map(mapping)\n",
    "\n",
    "    mapping = {'Month-to-Month':0, 'One Year':1, 'Two Year':2}\n",
    "    output_df['contract_type'] = df['contract_type'].map(mapping)\n",
    "\n",
    "    # One-hot encoding\n",
    "    # one_hot_encoder = OneHotEncoder()\n",
    "    # one_hot_encoded_cols = [\"payment_method\", \"internet_type\"]\n",
    "    # encoded_df = pd.DataFrame(one_hot_encoder.fit_transform(df[one_hot_encoded_cols]))\n",
    "    # encoded_df.columns = one_hot_encoder.get_feature_names_out(one_hot_encoded_cols)\n",
    "    # print(encoded_df.head())\n",
    "\n",
    "    # One-hot encoding\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    one_hot_encoded_cols = [\"payment_method\", \"internet_type\"]\n",
    "    encoded_features = one_hot_encoder.fit_transform(df[one_hot_encoded_cols])\n",
    "    encoded_df = pd.DataFrame(encoded_features.toarray(), columns=one_hot_encoder.get_feature_names_out(one_hot_encoded_cols))\n",
    "    output_df = pd.concat([output_df, encoded_df], axis=1)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    output_df['tenure_months'] = scaler.fit_transform(df[['tenure_months']])\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_acc_usage_df(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the account usage dataframe as below:\n",
    "    Scale the following columns:\n",
    "    - avg_long_distance_fee_monthly\n",
    "    - total_long_distance_fee\n",
    "    - avg_gb_download_monthly\n",
    "    - total_monthly_fee\n",
    "    - total_chargers_quarter\n",
    "    - total_refunds\n",
    "    Converts following col to 1/0:\n",
    "    - stream_move\n",
    "    - stream_music\n",
    "    - stream_tv\n",
    "    \"\"\"\n",
    "    # Create new df\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # Copying over acc_id\n",
    "    output_df['account_id'] = df['account_id']\n",
    "\n",
    "    # Converting yes/no to 1/0\n",
    "    mapping = {'Yes':1, 'No':0}\n",
    "\n",
    "    output_df['stream_movie'] = df['stream_movie'].map(mapping)\n",
    "    output_df['stream_music'] = df['stream_music'].map(mapping)\n",
    "    output_df['stream_tv'] = df['stream_tv'].map(mapping)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    output_df['avg_long_distance_fee_monthly'] = scaler.fit_transform(df[['avg_long_distance_fee_monthly']])\n",
    "    output_df['total_long_distance_fee'] = scaler.fit_transform(df[['total_long_distance_fee']])\n",
    "    output_df['avg_gb_download_monthly'] = scaler.fit_transform(df[['avg_gb_download_monthly']])\n",
    "    output_df['total_monthly_fee'] = scaler.fit_transform(df[['total_monthly_fee']])\n",
    "    output_df['total_charges_quarter'] = scaler.fit_transform(df[['total_charges_quarter']])\n",
    "    output_df['total_refunds'] = scaler.fit_transform(df[['total_refunds']])\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_churn_df(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the churn status dataframe as below:\n",
    "    Convert following col to 1/0:\n",
    "    - churn_label\n",
    "\n",
    "    Binary encodes:\n",
    "    - churn_category\n",
    "    \n",
    "    Label-encodes:\n",
    "    - status\n",
    "\n",
    "    Drops the following:\n",
    "    - churn_reason -> Not planning to do NLP\n",
    "    \"\"\"\n",
    "    # Create new df\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # Copying over acc_id\n",
    "    output_df['customer_id'] = df['customer_id']\n",
    "\n",
    "    # Converting yes/no to 1/0\n",
    "    # Additional step to check status \n",
    "    output_df['churn_label'] = df['churn_label'].fillna(0)\n",
    "    output_df.loc[df['status'] == 'Churned', 'churn_label'] = 1\n",
    "    mapping = {'Yes':1, 'No':0, }\n",
    "    output_df['churn_label'] = df['churn_label'].map(mapping)\n",
    "\n",
    "    # Binary Encoding\n",
    "    binary_encoder = BinaryEncoder(cols=['churn_category'])\n",
    "    binary_encoder.fit_transform(df['churn_category'])\n",
    "    churn_cat = binary_encoder.transform(df['churn_category'])\n",
    "    output_df = pd.concat([output_df, churn_cat], axis=1)\n",
    "\n",
    "    # Label Encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    output_df['status'] = label_encoder.fit_transform(df['status'])\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_city_df(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the city dataframe as below:\n",
    "    Min-max scales population column\n",
    "    Keep area_id and population only\n",
    "    \"\"\"\n",
    "    # Creating new df\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # Copying over area_id\n",
    "    output_df['zip_code'] = df['zip_code']\n",
    "\n",
    "    # Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    output_df['population'] = scaler.fit_transform(df[['population']])\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_customer_df(df:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the customer dataframe as below:\n",
    "    Convert following col to 1/0:\n",
    "    - senior_citizen\n",
    "    - married\n",
    "    - gender (1 for male, 0 for female)\n",
    "    \"\"\"\n",
    "    # Create new df\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    # Copying over customer_id, zip_code\n",
    "    output_df['customer_id'] = df['customer_id']\n",
    "    output_df['zip_code'] = df['zip_code']\n",
    "\n",
    "    # Converting columns to 1/0\n",
    "    mapping = {'Yes':1, 'No':0, \"Male\":1, \"Female\":0}\n",
    "    output_df['senior_citizen'] = df['senior_citizen'].map(mapping)\n",
    "    output_df['married'] = df['married'].map(mapping)\n",
    "    output_df['gender'] = df['gender'].map(mapping)\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing all CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dfs from CSV\n",
    "ACCOUNT_DF = pd.read_csv(ACC_PATH)\n",
    "ACCOUNT_USAGE_DF = pd.read_csv(ACC_USAGE_PATH)\n",
    "CHURN_STATUS_DF = pd.read_csv(CHURN_STATUS_PATH)\n",
    "CITY_DF = pd.read_csv(CITY_PATH)\n",
    "CUSTOMER_DF = pd.read_csv(CUSTOMER_PATH)\n",
    "\n",
    "# Preprocessing dfs\n",
    "account_df = preprocess_acc_df(ACCOUNT_DF)\n",
    "account_usage_df = preprocess_acc_usage_df(ACCOUNT_USAGE_DF)\n",
    "churn_status_df = preprocess_churn_df(CHURN_STATUS_DF)\n",
    "city_df = preprocess_city_df(CITY_DF)\n",
    "customer_df = preprocess_customer_df(CUSTOMER_DF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining customer and account tables on customer_id\n",
    "df = pd.merge(customer_df, account_df, on='customer_id', how='inner')\n",
    "# Joining df with account_usage_df on account_id\n",
    "df = pd.merge(df, account_usage_df, on='account_id', how='inner')\n",
    "# Joining df with churn_status_df on customer_id\n",
    "df = pd.merge(df, churn_status_df, on='customer_id', how='inner')\n",
    "# Joining df with city_df on area_id\n",
    "df = pd.merge(df, city_df, on='zip_code', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
